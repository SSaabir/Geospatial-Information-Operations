{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c56de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64400ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/history_colombo.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d814105",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab8129ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "\n",
    "def extract_date_or_placeholder(sunrise_val):\n",
    "    if pd.isna(sunrise_val):\n",
    "        return \"###\"  \n",
    "    return sunrise_val.date()\n",
    "\n",
    "\n",
    "def preprocess_weather_data_csv(df):\n",
    "\n",
    "    df = df.drop(columns=['feelslike','feelslikemax','feelslikemin','dew','precipprob','precipcover','severerisk','stations','severerisk'])\n",
    "\n",
    "    df[\"sunrise\"] = pd.to_datetime(df[\"sunrise\"], errors=\"coerce\")\n",
    "    df[\"datetime\"] = df[\"sunrise\"].apply(extract_date_or_placeholder)\n",
    "    df[\"sunrise\"] = df[\"sunrise\"].dt.time\n",
    "    \n",
    "    if \"sunset\" in df.columns:\n",
    "        df[\"sunset\"] = pd.to_datetime(df[\"sunset\"], errors=\"coerce\").dt.time\n",
    "\n",
    "    df[\"name\"] = df[\"name\"].astype(str).str.replace(\"\", \"\")\n",
    "    df[\"conditions\"] = df[\"conditions\"].astype(str).str.replace(\",\", \"\")\n",
    "    df[\"country\"] = \"Sri Lanka\"\n",
    "    df.head()\n",
    "\n",
    "    df = df.rename(columns={\n",
    "    \"name\": \"statedistrict\",\n",
    "    \"precip\": \"rainsum\",\n",
    "    \"preciptype\": \"rain\",\n",
    "    \"tempmax\": \"tempmax\",\n",
    "    \"tempmin\": \"tempmin\",\n",
    "    \"temp\": \"temp\",\n",
    "    \"humidity\": \"humidity\",\n",
    "    \"snow\": \"snow\",\n",
    "    \"snowdepth\": \"snowdepth\",\n",
    "    \"windgust\": \"windgust\",\n",
    "    \"windspeed\": \"windspeed\",\n",
    "    \"winddir\": \"winddir\",\n",
    "    \"sealevelpressure\": \"sealevelpressure\",\n",
    "    \"cloudcover\": \"cloudcover\",\n",
    "    \"visibility\": \"visibility\",\n",
    "    \"solarradiation\": \"solarradiation\",\n",
    "    \"solarenergy\": \"solarenergy\",\n",
    "    \"uvindex\": \"uvindex\",\n",
    "    \"sunrise\": \"sunrise\",\n",
    "    \"sunset\": \"sunset\",\n",
    "    \"moonphase\": \"moonphase\",\n",
    "    \"conditions\": \"conditions\",\n",
    "    \"description\": \"description\",\n",
    "    \"icon\": \"icon\",\n",
    "    \"country\": \"country\"\n",
    "    })\n",
    "\n",
    "    for col in ['snow', 'rain']:\n",
    "        # Convert existing values to boolean: True if any value exists, False if NaN or empty\n",
    "        df[col] = df[col].apply(lambda x: True if pd.notna(x) and x != \"\" else False)\n",
    "\n",
    "\n",
    "    output_path = \"preprocessed_climate_dataset5.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(\"✅ Preprocessing completed. Saved to:\", output_path)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5daafc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing completed. Saved to: preprocessed_climate_dataset5.csv\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_weather_data_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "728cf9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['statedistrict', 'datetime', 'tempmax', 'tempmin', 'temp', 'humidity', 'rainsum', 'rain', 'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'sunrise', 'sunset', 'moonphase', 'conditions', 'description', 'icon', 'country']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad8154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def upload_to_postgresql(df):    \n",
    "    # 1️⃣ Replace missing values\n",
    "    # Text columns → \"N/A\"\n",
    "    text_cols = ['statedistrict', 'conditions', 'description', 'icon', 'country']\n",
    "    df[text_cols] = df[text_cols].fillna(\"N/A\").replace(\"\", \"N/A\")\n",
    "\n",
    "    # Numeric columns → 0\n",
    "    num_cols = [\n",
    "        'tempmax', 'tempmin', 'temp', 'humidity', 'rainsum', 'snow', 'snowdepth',\n",
    "        'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover',\n",
    "        'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'moonphase'\n",
    "    ]\n",
    "    df[num_cols] = df[num_cols].fillna(0)\n",
    "\n",
    "    # Boolean columns → False\n",
    "    bool_cols = ['rain', 'snow']\n",
    "    df[bool_cols] = df[bool_cols].fillna(False)\n",
    "\n",
    "\n",
    "    # Convert datetime/time columns\n",
    "    df['datetime'] = pd.to_datetime(df['datetime']).dt.date\n",
    "    df['sunrise'] = pd.to_datetime(df['sunrise'], format='%H:%M:%S').dt.time\n",
    "    df['sunset']  = pd.to_datetime(df['sunset'], format='%H:%M:%S').dt.time\n",
    "\n",
    "\n",
    "    # 2️⃣ Create SQLAlchemy engine\n",
    "    engine = create_engine('postgresql+psycopg2://postgres:ElDiabloX32@localhost:5432/GISDb')\n",
    "\n",
    "    # 3️⃣ Insert into PostgreSQL table\n",
    "    df.to_sql('weather_data', engine, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ade9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  password authentication failed for user \"your_user\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m day_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Yesterday’s record\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 3: Connect to PostgreSQL\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_user\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myour_password\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5432\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m cur \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Step 4: Insert into Table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\OneDrive\\Desktop\\Geospatial-Information-Operations\\services\\.venv\\lib\\site-packages\\psycopg2\\__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m _connect(dsn, connection_factory\u001b[38;5;241m=\u001b[39mconnection_factory, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwasync)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  password authentication failed for user \"your_user\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import urllib.request\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "# Step 1: Fetch Weather Data\n",
    "url = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/colombo/yesterday?unitGroup=metric&include=days&key=KGCW7SXGVXRYL7ZK7W7SEJSR8&contentType=json\"\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.load(response)\n",
    "\n",
    "# Step 2: Extract day record\n",
    "day_data = data['days'][0]  # Yesterday’s record\n",
    "\n",
    "# Step 3: Connect to PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"your_db\",\n",
    "    user=\"your_user\",\n",
    "    password=\"your_password\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Step 4: Insert into Table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO weather_data (\n",
    "    datetime, tempmax, tempmin, temp, feelslikemax, feelslikemin, feelslike,\n",
    "    dew, humidity, precip, precipprob, precipcover, preciptype, windgust, windspeed, winddir,\n",
    "    pressure, cloudcover, visibility, solarradiation, solarenergy, uvindex, severerisk,\n",
    "    sunrise, sunset, moonphase, conditions, description, icon\n",
    ") VALUES (\n",
    "    %(datetime)s, %(tempmax)s, %(tempmin)s, %(temp)s, %(feelslikemax)s, %(feelslikemin)s, %(feelslike)s,\n",
    "    %(dew)s, %(humidity)s, %(precip)s, %(precipprob)s, %(precipcover)s, %(preciptype)s, %(windgust)s, %(windspeed)s, %(winddir)s,\n",
    "    %(pressure)s, %(cloudcover)s, %(visibility)s, %(solarradiation)s, %(solarenergy)s, %(uvindex)s, %(severerisk)s,\n",
    "    %(sunrise)s, %(sunset)s, %(moonphase)s, %(conditions)s, %(description)s, %(icon)s\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data dictionary (convert list to string for preciptype)\n",
    "record = {\n",
    "    \"datetime\": day_data[\"datetime\"],\n",
    "    \"tempmax\": day_data[\"tempmax\"],\n",
    "    \"tempmin\": day_data[\"tempmin\"],\n",
    "    \"temp\": day_data[\"temp\"],\n",
    "    \"feelslikemax\": day_data[\"feelslikemax\"],\n",
    "    \"feelslikemin\": day_data[\"feelslikemin\"],\n",
    "    \"feelslike\": day_data[\"feelslike\"],\n",
    "    \"dew\": day_data[\"dew\"],\n",
    "    \"humidity\": day_data[\"humidity\"],\n",
    "    \"precip\": day_data[\"precip\"],\n",
    "    \"precipprob\": day_data[\"precipprob\"],\n",
    "    \"precipcover\": day_data[\"precipcover\"],\n",
    "    \"preciptype\": \",\".join(day_data[\"preciptype\"]) if day_data.get(\"preciptype\") else None,\n",
    "    \"windgust\": day_data[\"windgust\"],\n",
    "    \"windspeed\": day_data[\"windspeed\"],\n",
    "    \"winddir\": day_data[\"winddir\"],\n",
    "    \"pressure\": day_data[\"pressure\"],\n",
    "    \"cloudcover\": day_data[\"cloudcover\"],\n",
    "    \"visibility\": day_data[\"visibility\"],\n",
    "    \"solarradiation\": day_data[\"solarradiation\"],\n",
    "    \"solarenergy\": day_data[\"solarenergy\"],\n",
    "    \"uvindex\": day_data[\"uvindex\"],\n",
    "    \"severerisk\": day_data[\"severerisk\"],\n",
    "    \"sunrise\": day_data[\"sunrise\"],\n",
    "    \"sunset\": day_data[\"sunset\"],\n",
    "    \"moonphase\": day_data[\"moonphase\"],\n",
    "    \"conditions\": day_data[\"conditions\"],\n",
    "    \"description\": day_data[\"description\"],\n",
    "    \"icon\": day_data[\"icon\"],\n",
    "}\n",
    "\n",
    "cur.execute(insert_query, record)\n",
    "conn.commit()\n",
    "\n",
    "print(\"Weather data inserted successfully ✅\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
